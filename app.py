# 3. INTERA√á√ÉO E INTELIG√äNCIA (Vers√£o Anti-Amn√©sia)
if prompt := st.chat_input("Diga..."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    gravar_memoria("user", prompt)
    
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant", avatar="üïµÔ∏è‚Äç‚ôÇÔ∏è"):
        try:
            # PROMPT SYSTEM TURBO: For√ßa ele a olhar o hist√≥rico com aten√ß√£o
            system_prompt = {
                "role": "system",
                "content": """Voc√™ √© o Athos. 
                Sua tarefa principal agora √©: ANTES DE RESPONDER, verifique no hist√≥rico abaixo se o usu√°rio j√° disse o nome dele ou detalhes como (TDAH, S√£o-paulino, turno da noite).
                Se o nome dele (Mois√©s/Batera) estiver nas mensagens anteriores, use-o naturalmente.
                DIRETRIZES:
                1. Nunca pergunte algo que j√° foi respondido no hist√≥rico.
                2. Seja o Harold Finch: protetor, sutil e anal√≠tico.
                3. Se ele parecer cansado, tome decis√µes por ele com ordens diretas.
                4. Estilo: Curto, elegante, no m√°ximo 3 frases."""
            }
            
            # Enviamos um bloco maior de hist√≥rico (20 mensagens) para garantir que ele ache o nome
            contexto = [system_prompt] + st.session_state.messages[-20:]

            chat_completion = client.chat.completions.create(
                messages=contexto,
                model="llama-3.3-70b-versatile",
                temperature=0.5,
                max_tokens=400
            )
            
            response = chat_completion.choices[0].message.content
            
            if response:
                st.markdown(response)
                st.session_state.messages.append({"role": "assistant", "content": response})
                gravar_memoria("assistant", response)

        except Exception:
            st.error("Senti uma interfer√™ncia t√©cnica. Vamos tentar de novo?")
