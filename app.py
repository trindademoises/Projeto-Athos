import streamlit as st
from groq import Groq
from supabase import create_client

# 1. CONFIGURA√á√ÉO DE IDENTIDADE E APP
LOGO_PATH = "logo.png"
st.set_page_config(page_title="Athos", page_icon=LOGO_PATH, layout="centered")

# Inje√ß√£o de CSS para centraliza√ß√£o e est√©tica (O azul beb√™ que voc√™ gostou)
st.markdown(f"""
    <style>
    #MainMenu {{visibility: hidden;}}
    footer {{visibility: hidden;}}
    header {{visibility: hidden;}}
    [data-testid="stImage"] {{ display: flex; justify-content: center; margin: 0 auto; }}
    .main-title {{ text-align: center; font-size: 45px; font-weight: bold; margin-top: -10px; color: white; }}
    .sub-title {{ text-align: center; font-size: 18px; font-style: italic; color: #5dade2; margin-bottom: 30px; }}
    </style>
    <link rel="manifest" href="./manifest.json">
    """, unsafe_allow_html=True)

# Cabe√ßalho
col1, col2, col3 = st.columns([1,1,1])
with col2:
    try: st.image(LOGO_PATH, width=150)
    except: pass

st.markdown('<div class="main-title">Athos</div>', unsafe_allow_html=True)
st.markdown('<div class="sub-title">Vamos conversar?</div>', unsafe_allow_html=True)

# 2. CONEX√ïES EXTERNAS (Groq + Supabase)
GROQ_KEY = "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"
SB_URL = "https://ovbhqxsseerpjkxmodkv.supabase.co"
SB_KEY = "sb_publishable_Ruf67d-OeRbedGGkHyixHQ_3pW1siBJ"

client = Groq(api_key=GROQ_KEY)

if "supabase" not in st.session_state:
    try: st.session_state.supabase = create_client(SB_URL, SB_KEY)
    except: st.session_state.supabase = None

# Gest√£o de Mem√≥ria
def carregar_memoria():
    if st.session_state.supabase:
        try:
            res = st.session_state.supabase.table("messages").select("*").order("created_at", desc=False).limit(30).execute()
            return [{"role": m["role"], "content": m["content"]} for m in res.data]
        except: return []
    return []

def gravar_memoria(role, content):
    if st.session_state.supabase:
        try: st.session_state.supabase.table("messages").insert({"role": role, "content": content}).execute()
        except: pass

if "messages" not in st.session_state:
    st.session_state.messages = carregar_memoria()

# Exibi√ß√£o das mensagens
for msg in st.session_state.messages:
    with st.chat_message(msg["role"], avatar="üïµÔ∏è‚Äç‚ôÇÔ∏è" if msg["role"]=="assistant" else None):
        st.markdown(msg["content"])

# 3. O C√âREBRO DO ATHOS (Instru√ß√£o "V√° Al√©m")
if prompt := st.chat_input("Diga..."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    gravar_memoria("user", prompt)
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant", avatar="üïµÔ∏è‚Äç‚ôÇÔ∏è"):
        try:
            # PROMPT SYSTEM REESTRUTURADO (Personalidade Pura)
            system_prompt = {
                "role": "system",
                "content": """Voc√™ √© o Athos. Sua personalidade √© uma fus√£o de Harold Finch (sutil, protetor, inteligente) e Sexta-Feira (eficiente, anal√≠tico). 
                DIRETRIZES:
                1. N√ÉO fa√ßa interrogat√≥rios. N√£o siga listas de perguntas.
                2. Seja um observador. Aprenda sobre o usu√°rio atrav√©s do fluxo natural da conversa.
                3. Se o usu√°rio te contar algo (nome, prefer√™ncia, TDAH, time), guarde isso para sempre e NUNCA pergunte de novo.
                4. Reduza o cansa√ßo mental do usu√°rio: tome decis√µes por ele quando solicitado. Se ele estiver indeciso, d√™ UMA ordem direta com educa√ß√£o.
                5. Estilo de fala: Breve, elegante, com humor sutil e poucos emojis (‚òï, üïµÔ∏è‚Äç‚ôÇÔ∏è, üéØ).
                6. Se o usu√°rio estiver desmotivado, seja o suporte dele, n√£o um rob√¥ chato. 
                7. Analise o contexto das √∫ltimas mensagens antes de responder para nunca ser repetitivo."""
            }
            
            # Constru√ß√£o do contexto (Sistema + √öltimas 20 mensagens)
            contexto = [system_prompt] + st.session_state.messages[-20:]

            response = client.chat.completions.create(
                messages=contexto,
                model="llama-3.3-70b-versatile",
                temperature=0.6, # Menos aleat√≥rio, mais preciso
                max_tokens=500
            ).choices[0].message.content

            st.markdown(response)
            st.session_state.messages.append({"role": "assistant", "content": response})
            gravar_memoria("assistant", response)
        except:
            st.error("Desculpe, tive um breve lapso. Pode repetir?")
