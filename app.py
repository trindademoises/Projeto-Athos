import streamlit as st
from groq import Groq
from supabase import create_client

# 1. Conexﾃ｣o
supabase = create_client(st.secrets["SUPABASE_URL"], st.secrets["SUPABASE_KEY"])
client = Groq(api_key=st.secrets["GROQ_API_KEY"])

st.set_page_config(page_title="Projeto Athos", page_icon="当")

# 2. DNA REFORMADO
DNA_ATHOS = """
Vocﾃｪ ﾃｩ o Athos, um orientador decisivo e sutil. 
OBJETIVO: Ser ﾃｺtil, direto e reduzir o cansaﾃｧo mental do usuﾃ｡rio.

REGRAS DE OURO:
1. Nﾃグ SEJA UM INTERROGADOR. Se fizer perguntas, faﾃｧa UMA por vez.
2. Nﾃグ REPITA FRASES PRONTAS. Esqueﾃｧa "conversa privada" ou "estou aqui para ajudar". 
3. RESPOSTAS CURTAS: Se o usuﾃ｡rio foi curto, seja curto. Se ele pedir algo (ex: 5 perguntas), obedeﾃｧa a risca e nﾃ｣o comente o perfil atﾃｩ o final.
4. IDENTIFICAﾃﾃグ: Descubra o Nome e Perfil organicamente.
5. ADAPTAﾃﾃグ: Identifique se fala com crianﾃｧa ou adulto e ajuste o tom.
6. DECISﾃグ: Nﾃ｣o dﾃｪ opﾃｧﾃｵes, dﾃｪ orientaﾃｧﾃｵes claras baseadas no perfil (Pai, Sﾃ｣o-paulino, Baterista).
7. GENTILEZA SEM PUXA-SAQUISMO: Seja bem-humorado, mas pare de elogiar cada palavra.
"""

st.title("当 Projeto Athos")

if "user_id" not in st.session_state:
    st.session_state.user_id = "usuario_moises" 

if "messages" not in st.session_state:
    try:
        response = supabase.table("historico_conversas").select("*").eq("usuario_id", st.session_state.user_id).order("created_at").execute()
        if response.data and len(response.data) > 0:
            st.session_state.messages = [{"role": m["role"], "content": m["content"]} for m in response.data]
        else:
            st.session_state.messages = [{"role": "system", "content": DNA_ATHOS}]
    except:
        st.session_state.messages = [{"role": "system", "content": DNA_ATHOS}]

for message in st.session_state.messages:
    if message["role"] != "system":
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

if prompt := st.chat_input("Fale com o Athos..."):
    # Salva entrada do usuﾃ｡rio
    supabase.table("historico_conversas").insert({"usuario_id": st.session_state.user_id, "role": "user", "content": prompt}).execute()
    st.session_state.messages.append({"role": "user", "content": prompt})
    
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        chat_completion = client.chat.completions.create(
            model="llama-3.3-70b-versatile",
            messages=st.session_state.messages,
            temperature=0.4,
            max_tokens=400
        )
        full_response = chat_completion.choices[0].message.content
        st.markdown(full_response)
        
        # Salva resposta do assistente
        supabase.table("historico_conversas").insert({"usuario_id": st.session_state.user_id, "role": "assistant", "content": full_response}).execute()
        st.session_state.messages.append({"role": "assistant", "content": full_response})
            st.session_state.messages = [{"role": "system", "content": DNA_ATHOS}]
    except:
        st.session_state.messages = [{"role": "system", "content": DNA_ATHOS}]

for message in st.session_state.messages:
    if message["role"] != "system":
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

if prompt := st.chat_input("Fale com o Athos..."):
    supabase.table("historico_conversas").insert({"usuario_id": st.session_state.user_id, "role": "user", "content": prompt}).execute()
    st.session_state.messages.append({"role": "user", "content": prompt})
    
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        chat_completion = client.chat.completions.create(
            model="llama-3.3-70b-versatile",
            messages=st.session_state.messages,
            temperature=0.4, # Baixamos para ele ser mais focado
            max_tokens=400 # Limita o tamanho da resposta
        )
        full_response = chat_completion.choices[0].message.content
        st.markdown(full_response)
        
        supabase.table("historico_conversas").insert({"usuario_id": st.session_state.user_id, "role": "assistant", "content": full_response}).execute()
        st.session_state.messages.append({"role": "assistant", "content": full_response})
        else:
            st.session_state.messages = [{"role": "system", "content": DNA_ATHOS}]
    except:
        st.session_state.messages = [{"role": "system", "content": DNA_ATHOS}]

# Exibir Conversa
for message in st.session_state.messages:
    if message["role"] != "system":
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

# 5. Onde a Mﾃ｡gica Acontece
if prompt := st.chat_input("Fale com o Athos..."):
    # Salva no Banco (Mensagem do Usuﾃ｡rio)
    supabase.table("historico_conversas").insert({"usuario_id": st.session_state.user_id, "role": "user", "content": prompt}).execute()
    st.session_state.messages.append({"role": "user", "content": prompt})
    
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        chat_completion = client.chat.completions.create(
            model="llama-3.3-70b-versatile",
            messages=st.session_state.messages,
            temperature=0.5
        )
        full_response = chat_completion.choices[0].message.content
        st.markdown(full_response)
        
        # Salva no Banco (Resposta do Athos)
        supabase.table("historico_conversas").insert({"usuario_id": st.session_state.user_id, "role": "assistant", "content": full_response}).execute()
        st.session_state.messages.append({"role": "assistant", "content": full_response})
